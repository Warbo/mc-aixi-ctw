<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<title>MC-AIXI-CTW: Agent Class Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<link href="doxygen.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<!-- Generated by Doxygen 1.7.1 -->
<div class="navigation" id="top">
  <div class="tabs">
    <ul class="tablist">
      <li><a href="main.html"><span>Main&nbsp;Page</span></a></li>
      <li class="current"><a href="annotated.html"><span>Data&nbsp;Structures</span></a></li>
      <li><a href="files.html"><span>Files</span></a></li>
    </ul>
  </div>
  <div class="tabs2">
    <ul class="tablist">
      <li><a href="annotated.html"><span>Data&nbsp;Structures</span></a></li>
      <li><a href="hierarchy.html"><span>Class&nbsp;Hierarchy</span></a></li>
      <li><a href="functions.html"><span>Data&nbsp;Fields</span></a></li>
    </ul>
  </div>
</div>
<div class="header">
  <div class="summary">
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="#pri-methods">Private Member Functions</a> &#124;
<a href="#pri-attribs">Private Attributes</a>  </div>
  <div class="headertitle">
<h1>Agent Class Reference</h1>  </div>
</div>
<div class="contents">
<!-- doxytag: class="Agent" -->
<p><code>#include &lt;<a class="el" href="agent_8hpp_source.html">agent.hpp</a>&gt;</code></p>
<div class="dynheader">
Collaboration diagram for Agent:</div>
<div class="dyncontent">
<div class="center"><img src="classAgent__coll__graph.png" border="0" usemap="#Agent_coll__map" alt="Collaboration graph"/></div>
<map name="Agent_coll__map" id="Agent_coll__map">
<area shape="rect" title="STL class." alt="" coords="15,120,135,149"/><area shape="rect" href="classContextTree.html" title="ContextTree" alt="" coords="159,120,249,149"/><area shape="rect" href="classCTNode.html" title="CTNode" alt="" coords="137,5,204,35"/><area shape="rect" href="classSearchNode.html" title="SearchNode" alt="" coords="447,120,537,149"/><area shape="rect" href="classEnvironment.html" title="Environment" alt="" coords="273,120,367,149"/></map>
<center><span class="legend">[<a target="top" href="graph_legend.html">legend</a>]</span></center></div>
<table class="memberdecls">
<tr><td colspan="2"><h2><a name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr><td class="memItemLeft" align="right" valign="top"><a class="el" href="main_8hpp.html#afc9884d9296b2bc1fc412248318128a9">age_t</a>&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAgent.html#a546d7641c9a2ba8cf6d5b7427aeef5a3">age</a> () const </td></tr>
<tr><td class="memItemLeft" align="right" valign="top">&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAgent.html#aa025b178ab6eaaa87268e7f023c95150">Agent</a> (<a class="el" href="main_8hpp.html#a0ff5cac1a4007bb330b7d9939650c283">options_t</a> &amp;options, <a class="el" href="classEnvironment.html">Environment</a> const &amp;env)</td></tr>
<tr><td class="memItemLeft" align="right" valign="top"><a class="el" href="main_8hpp.html#a008010a51f193f33b2e94c75e10d30b2">reward_t</a>&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAgent.html#ae80a471a3771c94491ef8ffd6817a87a">averageReward</a> () const </td></tr>
<tr><td class="memItemLeft" align="right" valign="top"><a class="el" href="main_8hpp.html#aae5c472255c22ac4ca225a8b856d6617">action_t</a>&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAgent.html#a4d7516fc4fa235579bec105c59a116a5">genAction</a> () const </td></tr>
<tr><td class="memItemLeft" align="right" valign="top">void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAgent.html#a355ffd0b425d575d458f55a6d3be3146">genPercept</a> (<a class="el" href="main_8hpp.html#ae876c1434cd64208efe3bc215e4391f4">percept_t</a> &amp;observation, <a class="el" href="main_8hpp.html#ae876c1434cd64208efe3bc215e4391f4">percept_t</a> &amp;reward)</td></tr>
<tr><td class="memItemLeft" align="right" valign="top">void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAgent.html#a5f1e9d7b8406d71ea2b031c259662496">genPerceptAndUpdate</a> (<a class="el" href="main_8hpp.html#ae876c1434cd64208efe3bc215e4391f4">percept_t</a> &amp;observation, <a class="el" href="main_8hpp.html#ae876c1434cd64208efe3bc215e4391f4">percept_t</a> &amp;reward)</td></tr>
<tr><td class="memItemLeft" align="right" valign="top"><a class="el" href="main_8hpp.html#aae5c472255c22ac4ca225a8b856d6617">action_t</a>&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAgent.html#ae785bc53214dc592055779ad40004dee">genRandomAction</a> () const </td></tr>
<tr><td class="memItemLeft" align="right" valign="top">double&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAgent.html#a26f277b7001f56a48219c24d702d8c3e">getPredictedActionProb</a> (<a class="el" href="main_8hpp.html#aae5c472255c22ac4ca225a8b856d6617">action_t</a> action)</td></tr>
<tr><td class="memItemLeft" align="right" valign="top">int&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAgent.html#a94f6ec9baf65e862f5643857ee7c575b">historySize</a> () const </td></tr>
<tr><td class="memItemLeft" align="right" valign="top">int&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAgent.html#a4f86f50cdc91387ea31aef3e14e61912">horizon</a> () const </td></tr>
<tr><td class="memItemLeft" align="right" valign="top"><a class="el" href="agent_8hpp.html#accbaf2fbd73874d4101d738a22205dc3">update_t</a>&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAgent.html#a8d732dca2ad60a250c65f3c2112fba34">lastUpdate</a> (void) const </td></tr>
<tr><td class="memItemLeft" align="right" valign="top">int&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAgent.html#a83cbf224d699d2ef2ce74848656cc3f9">maxAction</a> () const </td></tr>
<tr><td class="memItemLeft" align="right" valign="top">int&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAgent.html#a4dc611cbe426034f0af35823a489221b">maxBitsNeeded</a> () const </td></tr>
<tr><td class="memItemLeft" align="right" valign="top">double&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAgent.html#a5a234203ccae48c9a241a6e40c7887f6">maxReward</a> () const </td></tr>
<tr><td class="memItemLeft" align="right" valign="top">void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAgent.html#a464e7b5139527b39986d6f53487b6f6b">modelRevert</a> (const <a class="el" href="classModelUndo.html">ModelUndo</a> &amp;mu)</td></tr>
<tr><td class="memItemLeft" align="right" valign="top">int&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAgent.html#ad859620dd26557127c7221311089e00e">modelSize</a> () const </td></tr>
<tr><td class="memItemLeft" align="right" valign="top">void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAgent.html#a5d7e42a9677cc6c5a8bcb236f36ddb0a">modelUpdate</a> (<a class="el" href="main_8hpp.html#ae876c1434cd64208efe3bc215e4391f4">percept_t</a> observation, <a class="el" href="main_8hpp.html#ae876c1434cd64208efe3bc215e4391f4">percept_t</a> reward)</td></tr>
<tr><td class="memItemLeft" align="right" valign="top">void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAgent.html#adf4845b694cd4e2f6b9b02270b2e6040">modelUpdate</a> (<a class="el" href="main_8hpp.html#aae5c472255c22ac4ca225a8b856d6617">action_t</a> action)</td></tr>
<tr><td class="memItemLeft" align="right" valign="top">double&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAgent.html#af73c945cfc7f20619bbaea03c07c72be">perceptProbability</a> (<a class="el" href="main_8hpp.html#ae876c1434cd64208efe3bc215e4391f4">percept_t</a> observation, <a class="el" href="main_8hpp.html#ae876c1434cd64208efe3bc215e4391f4">percept_t</a> reward) const </td></tr>
<tr><td class="memItemLeft" align="right" valign="top"><a class="el" href="main_8hpp.html#a008010a51f193f33b2e94c75e10d30b2">reward_t</a>&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAgent.html#a0f38a1f8ff4ca66eb1adaea3c38261d9">playout</a> (int horizon)</td></tr>
<tr><td class="memItemLeft" align="right" valign="top">void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAgent.html#a5dc4ba18b66815d10359e458b0e5d867">reset</a> (void)</td></tr>
<tr><td class="memItemLeft" align="right" valign="top"><a class="el" href="main_8hpp.html#aae5c472255c22ac4ca225a8b856d6617">action_t</a>&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAgent.html#ac2477fa04e05470c2c7dd80ae291a4fc">search</a> (void)</td></tr>
<tr><td class="memItemLeft" align="right" valign="top"><a class="el" href="main_8hpp.html#a008010a51f193f33b2e94c75e10d30b2">reward_t</a>&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAgent.html#af0956c4cf5de1879b5c0efb3ad1e0f67">totalReward</a> () const </td></tr>
<tr><td class="memItemLeft" align="right" valign="top">&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAgent.html#ab8dd8d152605cf1339fed595376e83cb">~Agent</a> ()</td></tr>
<tr><td colspan="2"><h2><a name="pri-methods"></a>
Private Member Functions</h2></td></tr>
<tr><td class="memItemLeft" align="right" valign="top"><a class="el" href="main_8hpp.html#aae5c472255c22ac4ca225a8b856d6617">action_t</a>&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAgent.html#add792862f01878c70bb85dfcb3f264a6">decodeAction</a> (const <a class="el" href="main_8hpp.html#a96913eb6aee99146c546467f52cf18dc">symbol_list_t</a> &amp;symlist) const </td></tr>
<tr><td class="memItemLeft" align="right" valign="top"><a class="el" href="main_8hpp.html#ae876c1434cd64208efe3bc215e4391f4">percept_t</a>&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAgent.html#a835df7db4c40e4eca55ab60872ca9dd9">decodeObservation</a> (const <a class="el" href="main_8hpp.html#a96913eb6aee99146c546467f52cf18dc">symbol_list_t</a> &amp;symlist) const </td></tr>
<tr><td class="memItemLeft" align="right" valign="top">void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAgent.html#a399272975e29b329d25d161de56d3933">decodePercept</a> (const <a class="el" href="main_8hpp.html#a96913eb6aee99146c546467f52cf18dc">symbol_list_t</a> &amp;symlist, <a class="el" href="main_8hpp.html#ae876c1434cd64208efe3bc215e4391f4">percept_t</a> &amp;observation, <a class="el" href="main_8hpp.html#ae876c1434cd64208efe3bc215e4391f4">percept_t</a> &amp;reward)</td></tr>
<tr><td class="memItemLeft" align="right" valign="top"><a class="el" href="main_8hpp.html#ae876c1434cd64208efe3bc215e4391f4">percept_t</a>&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAgent.html#ac705f77f13d2e823880e884cf78aab68">decodeReward</a> (const <a class="el" href="main_8hpp.html#a96913eb6aee99146c546467f52cf18dc">symbol_list_t</a> &amp;symlist) const </td></tr>
<tr><td class="memItemLeft" align="right" valign="top">void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAgent.html#a25182721cd10e6de8d1a1d067040ab5d">encodeAction</a> (<a class="el" href="main_8hpp.html#a96913eb6aee99146c546467f52cf18dc">symbol_list_t</a> &amp;symlist, <a class="el" href="main_8hpp.html#aae5c472255c22ac4ca225a8b856d6617">action_t</a> action) const </td></tr>
<tr><td class="memItemLeft" align="right" valign="top">void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAgent.html#a95df691c5e041ad619f07632da6fa706">encodePercept</a> (<a class="el" href="main_8hpp.html#a96913eb6aee99146c546467f52cf18dc">symbol_list_t</a> &amp;symlist, <a class="el" href="main_8hpp.html#ae876c1434cd64208efe3bc215e4391f4">percept_t</a> observation, <a class="el" href="main_8hpp.html#ae876c1434cd64208efe3bc215e4391f4">percept_t</a> reward) const </td></tr>
<tr><td colspan="2"><h2><a name="pri-attribs"></a>
Private Attributes</h2></td></tr>
<tr><td class="memItemLeft" align="right" valign="top"><a class="el" href="classContextTree.html">ContextTree</a> *&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAgent.html#a74dd45989bc1b5128788cbe4a0f2ae37">m_ct</a></td></tr>
<tr><td class="memItemLeft" align="right" valign="top"><a class="el" href="classEnvironment.html">Environment</a> const &amp;&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAgent.html#aa5c1d62784eb31e8eb41cad1431dba53">m_env</a></td></tr>
<tr><td class="memItemLeft" align="right" valign="top">int&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAgent.html#abe3b766fdc5c7e7e1970b0e13de2cf3b">m_horizon</a></td></tr>
<tr><td class="memItemLeft" align="right" valign="top"><a class="el" href="agent_8hpp.html#accbaf2fbd73874d4101d738a22205dc3">update_t</a>&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAgent.html#ab2f8cb6e7035f0b88c2dc455d26cefc0">m_last_update</a></td></tr>
<tr><td class="memItemLeft" align="right" valign="top">int&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAgent.html#a6909f2e3a2431c7e6bc7a574cdea2c56">m_learning_period</a></td></tr>
<tr><td class="memItemLeft" align="right" valign="top">int&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAgent.html#a247ae06b17ed43159d3fffce0b444fa3">m_mc_simulations</a></td></tr>
<tr><td class="memItemLeft" align="right" valign="top"><a class="el" href="main_8hpp.html#a0ff5cac1a4007bb330b7d9939650c283">options_t</a> &amp;&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAgent.html#a4b5e2ba976ad0f397d0d0591ea7faebf">m_options</a></td></tr>
<tr><td class="memItemLeft" align="right" valign="top"><a class="el" href="classSearchNode.html">SearchNode</a> *&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAgent.html#a00b3ccf57df47e369a01b0a80b0155f3">m_search_tree</a></td></tr>
<tr><td class="memItemLeft" align="right" valign="top"><a class="el" href="main_8hpp.html#afc9884d9296b2bc1fc412248318128a9">age_t</a>&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAgent.html#acd27d5d9fa97749bffe84671cb9bb1ee">m_time_cycle</a></td></tr>
<tr><td class="memItemLeft" align="right" valign="top"><a class="el" href="main_8hpp.html#a008010a51f193f33b2e94c75e10d30b2">reward_t</a>&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAgent.html#a341264ac3d700120cfd1c50ab35c60ab">m_total_reward</a></td></tr>
</table>
<hr/><a name="_details"></a><h2>Detailed Description</h2>
<p>The <a class="el" href="classAgent.html">Agent</a> class represents a MC-AIXI-CTW agent. It includes much of the high-level logic for choosing suitable actions. In particular, the agent maintains an internal model of the environment using a context tree <a class="el" href="classAgent.html#a74dd45989bc1b5128788cbe4a0f2ae37">Agent::m_ct</a>. It uses this internal model to to predict the probability of future outcomes:</p>
<ul>
<li><a class="el" href="classAgent.html#a26f277b7001f56a48219c24d702d8c3e">Agent::getPredictedActionProb()</a></li>
<li><a class="el" href="classAgent.html#af73c945cfc7f20619bbaea03c07c72be">Agent::perceptProbability()</a></li>
</ul>
<p>as well as to generate actions and percepts according to the model distribution:</p>
<ul>
<li><a class="el" href="classAgent.html#a4d7516fc4fa235579bec105c59a116a5">Agent::genAction()</a></li>
<li><a class="el" href="classAgent.html#a355ffd0b425d575d458f55a6d3be3146">Agent::genPercept()</a></li>
<li><a class="el" href="classAgent.html#a5f1e9d7b8406d71ea2b031c259662496">Agent::genPerceptAndUpdate()</a></li>
<li><a class="el" href="classAgent.html#ae785bc53214dc592055779ad40004dee">Agent::genRandomAction()</a></li>
</ul>
<p>Actions are chosen via the UCT algorithm, which is orchestrated by a high-level search function and a playout policy:</p>
<ul>
<li><a class="el" href="classAgent.html#ac2477fa04e05470c2c7dd80ae291a4fc">Agent::search()</a></li>
<li><a class="el" href="classAgent.html#a0f38a1f8ff4ca66eb1adaea3c38261d9">Agent::playout()</a></li>
<li><a class="el" href="classAgent.html#abe3b766fdc5c7e7e1970b0e13de2cf3b">Agent::m_horizon</a></li>
<li><a class="el" href="classAgent.html#a247ae06b17ed43159d3fffce0b444fa3">Agent::m_mc_simulations</a></li>
<li><a class="el" href="classAgent.html#a00b3ccf57df47e369a01b0a80b0155f3">Agent::m_search_tree</a></li>
</ul>
<p>Several functions decode/encode actions and percepts between the corresponding types (i.e. <a class="el" href="main_8hpp.html#aae5c472255c22ac4ca225a8b856d6617">action_t</a>, <a class="el" href="main_8hpp.html#ae876c1434cd64208efe3bc215e4391f4">percept_t</a>) and generic representation by symbol lists:</p>
<ul>
<li><a class="el" href="classAgent.html#add792862f01878c70bb85dfcb3f264a6">Agent::decodeAction()</a></li>
<li><a class="el" href="classAgent.html#a835df7db4c40e4eca55ab60872ca9dd9">Agent::decodeObservation()</a></li>
<li><a class="el" href="classAgent.html#a399272975e29b329d25d161de56d3933">Agent::decodePercept()</a></li>
<li><a class="el" href="classAgent.html#ac705f77f13d2e823880e884cf78aab68">Agent::decodeReward()</a></li>
<li><a class="el" href="classAgent.html#a25182721cd10e6de8d1a1d067040ab5d">Agent::encodeAction()</a></li>
<li><a class="el" href="classAgent.html#a95df691c5e041ad619f07632da6fa706">Agent::encodePercept()</a></li>
</ul>
<p>There are various attributes which describe the agent and it's interaction with the environment so far:</p>
<ul>
<li><a class="el" href="classAgent.html#a546d7641c9a2ba8cf6d5b7427aeef5a3">Agent::age()</a></li>
<li><a class="el" href="classAgent.html#ae80a471a3771c94491ef8ffd6817a87a">Agent::averageReward()</a></li>
<li><a class="el" href="classAgent.html#a94f6ec9baf65e862f5643857ee7c575b">Agent::historySize()</a></li>
<li><a class="el" href="classAgent.html#a4f86f50cdc91387ea31aef3e14e61912">Agent::horizon()</a></li>
<li><a class="el" href="classAgent.html#a8d732dca2ad60a250c65f3c2112fba34">Agent::lastUpdate()</a></li>
<li><a class="el" href="classAgent.html#a83cbf224d699d2ef2ce74848656cc3f9">Agent::maxAction()</a></li>
<li><a class="el" href="classAgent.html#a4dc611cbe426034f0af35823a489221b">Agent::maxBitsNeeded()</a></li>
<li><a class="el" href="classAgent.html#a5a234203ccae48c9a241a6e40c7887f6">Agent::maxReward()</a></li>
<li><a class="el" href="classAgent.html#af0956c4cf5de1879b5c0efb3ad1e0f67">Agent::totalReward()</a> </li>
</ul>
<hr/><h2>Constructor &amp; Destructor Documentation</h2>
<a class="anchor" id="aa025b178ab6eaaa87268e7f023c95150"></a><!-- doxytag: member="Agent::Agent" ref="aa025b178ab6eaaa87268e7f023c95150" args="(options_t &amp;options, Environment const &amp;env)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">Agent::Agent </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="main_8hpp.html#a0ff5cac1a4007bb330b7d9939650c283">options_t</a> &amp;&nbsp;</td>
          <td class="paramname"> <em>options</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classEnvironment.html">Environment</a> const &amp;&nbsp;</td>
          <td class="paramname"> <em>env</em></td><td>&nbsp;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td><td></td>
        </tr>
      </table>
</div>
<div class="memdoc">
<p>Construct a learning agent from the configuration arguments and environmet. </p>
<dl><dt><b>Parameters:</b></dt><dd>
  <table border="0" cellspacing="2" cellpadding="0">
    <tr><td valign="top"></td><td valign="top"><em>options</em>&nbsp;</td><td>The configuration options. </td></tr>
    <tr><td valign="top"></td><td valign="top"><em>env</em>&nbsp;</td><td>The environment the agent will interact with. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="ab8dd8d152605cf1339fed595376e83cb"></a><!-- doxytag: member="Agent::~Agent" ref="ab8dd8d152605cf1339fed595376e83cb" args="()" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">Agent::~Agent </td>
          <td>(</td>
          <td class="paramtype">void&nbsp;</td>
          <td class="paramname"></td>
          <td>&nbsp;)&nbsp;</td>
          <td></td>
        </tr>
      </table>
</div>
<div class="memdoc">
<p>Destry the agent and the corresponding context tree. </p>

</div>
</div>
<hr/><h2>Member Function Documentation</h2>
<a class="anchor" id="a546d7641c9a2ba8cf6d5b7427aeef5a3"></a><!-- doxytag: member="Agent::age" ref="a546d7641c9a2ba8cf6d5b7427aeef5a3" args="() const " -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="main_8hpp.html#afc9884d9296b2bc1fc412248318128a9">age_t</a> Agent::age </td>
          <td>(</td>
          <td class="paramtype">void&nbsp;</td>
          <td class="paramname"></td>
          <td>&nbsp;)&nbsp;</td>
          <td> const</td>
        </tr>
      </table>
</div>
<div class="memdoc">
<p>Current age of the agent in cycles. </p>

</div>
</div>
<a class="anchor" id="ae80a471a3771c94491ef8ffd6817a87a"></a><!-- doxytag: member="Agent::averageReward" ref="ae80a471a3771c94491ef8ffd6817a87a" args="() const " -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="main_8hpp.html#a008010a51f193f33b2e94c75e10d30b2">reward_t</a> Agent::averageReward </td>
          <td>(</td>
          <td class="paramtype">void&nbsp;</td>
          <td class="paramname"></td>
          <td>&nbsp;)&nbsp;</td>
          <td> const</td>
        </tr>
      </table>
</div>
<div class="memdoc">
<p>The average reward received by the agent at each time step. </p>

</div>
</div>
<a class="anchor" id="add792862f01878c70bb85dfcb3f264a6"></a><!-- doxytag: member="Agent::decodeAction" ref="add792862f01878c70bb85dfcb3f264a6" args="(const symbol_list_t &amp;symlist) const " -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="main_8hpp.html#aae5c472255c22ac4ca225a8b856d6617">action_t</a> Agent::decodeAction </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="main_8hpp.html#a96913eb6aee99146c546467f52cf18dc">symbol_list_t</a> &amp;&nbsp;</td>
          <td class="paramname"> <em>symlist</em></td>
          <td>&nbsp;)&nbsp;</td>
          <td> const<code> [private]</code></td>
        </tr>
      </table>
</div>
<div class="memdoc">
<p>Decode an action from the beginning of a list of symbols. </p>
<dl><dt><b>Parameters:</b></dt><dd>
  <table border="0" cellspacing="2" cellpadding="0">
    <tr><td valign="top"></td><td valign="top"><em>symlist</em>&nbsp;</td><td>The symbol list to decode the action from. </td></tr>
  </table>
  </dd>
</dl>
<dl class="return"><dt><b>Returns:</b></dt><dd>The decoded action. </dd></dl>

</div>
</div>
<a class="anchor" id="a835df7db4c40e4eca55ab60872ca9dd9"></a><!-- doxytag: member="Agent::decodeObservation" ref="a835df7db4c40e4eca55ab60872ca9dd9" args="(const symbol_list_t &amp;symlist) const " -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="main_8hpp.html#ae876c1434cd64208efe3bc215e4391f4">percept_t</a> Agent::decodeObservation </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="main_8hpp.html#a96913eb6aee99146c546467f52cf18dc">symbol_list_t</a> &amp;&nbsp;</td>
          <td class="paramname"> <em>symlist</em></td>
          <td>&nbsp;)&nbsp;</td>
          <td> const<code> [private]</code></td>
        </tr>
      </table>
</div>
<div class="memdoc">
<p>Decode an observation from the beginning of a list of symbols. </p>
<dl><dt><b>Parameters:</b></dt><dd>
  <table border="0" cellspacing="2" cellpadding="0">
    <tr><td valign="top"></td><td valign="top"><em>symlist</em>&nbsp;</td><td>The symbol list to decode the observation from. </td></tr>
  </table>
  </dd>
</dl>
<dl class="return"><dt><b>Returns:</b></dt><dd>The decoded observation. </dd></dl>

</div>
</div>
<a class="anchor" id="a399272975e29b329d25d161de56d3933"></a><!-- doxytag: member="Agent::decodePercept" ref="a399272975e29b329d25d161de56d3933" args="(const symbol_list_t &amp;symlist, percept_t &amp;observation, percept_t &amp;reward)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void Agent::decodePercept </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="main_8hpp.html#a96913eb6aee99146c546467f52cf18dc">symbol_list_t</a> &amp;&nbsp;</td>
          <td class="paramname"> <em>symlist</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="main_8hpp.html#ae876c1434cd64208efe3bc215e4391f4">percept_t</a> &amp;&nbsp;</td>
          <td class="paramname"> <em>observation</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="main_8hpp.html#ae876c1434cd64208efe3bc215e4391f4">percept_t</a> &amp;&nbsp;</td>
          <td class="paramname"> <em>reward</em></td><td>&nbsp;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td><td><code> [private]</code></td>
        </tr>
      </table>
</div>
<div class="memdoc">
<p>Decode a percept (observation and reward) from the beginning of a list of symbols. </p>
<dl><dt><b>Parameters:</b></dt><dd>
  <table border="0" cellspacing="2" cellpadding="0">
    <tr><td valign="top"></td><td valign="top"><em>symlist</em>&nbsp;</td><td>The symbol list to decode the observation from. </td></tr>
    <tr><td valign="top"></td><td valign="top"><em>observation</em>&nbsp;</td><td>Receives the decoded observation. </td></tr>
    <tr><td valign="top"></td><td valign="top"><em>reward</em>&nbsp;</td><td>Receives the decoded reward. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="ac705f77f13d2e823880e884cf78aab68"></a><!-- doxytag: member="Agent::decodeReward" ref="ac705f77f13d2e823880e884cf78aab68" args="(const symbol_list_t &amp;symlist) const " -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="main_8hpp.html#ae876c1434cd64208efe3bc215e4391f4">percept_t</a> Agent::decodeReward </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="main_8hpp.html#a96913eb6aee99146c546467f52cf18dc">symbol_list_t</a> &amp;&nbsp;</td>
          <td class="paramname"> <em>symlist</em></td>
          <td>&nbsp;)&nbsp;</td>
          <td> const<code> [private]</code></td>
        </tr>
      </table>
</div>
<div class="memdoc">
<p>Decode a reward from the beginning of a list of symbols. </p>
<dl><dt><b>Parameters:</b></dt><dd>
  <table border="0" cellspacing="2" cellpadding="0">
    <tr><td valign="top"></td><td valign="top"><em>symlist</em>&nbsp;</td><td>The symbol list to decode the reward from. </td></tr>
  </table>
  </dd>
</dl>
<dl class="return"><dt><b>Returns:</b></dt><dd>The decoded reward. </dd></dl>

</div>
</div>
<a class="anchor" id="a25182721cd10e6de8d1a1d067040ab5d"></a><!-- doxytag: member="Agent::encodeAction" ref="a25182721cd10e6de8d1a1d067040ab5d" args="(symbol_list_t &amp;symlist, action_t action) const " -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void Agent::encodeAction </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="main_8hpp.html#a96913eb6aee99146c546467f52cf18dc">symbol_list_t</a> &amp;&nbsp;</td>
          <td class="paramname"> <em>symlist</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="main_8hpp.html#aae5c472255c22ac4ca225a8b856d6617">action_t</a>&nbsp;</td>
          <td class="paramname"> <em>action</em></td><td>&nbsp;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td><td> const<code> [private]</code></td>
        </tr>
      </table>
</div>
<div class="memdoc">
<p>Encode an action as a list of symbols. </p>
<dl><dt><b>Parameters:</b></dt><dd>
  <table border="0" cellspacing="2" cellpadding="0">
    <tr><td valign="top"></td><td valign="top"><em>symlist</em>&nbsp;</td><td>The symbol list to encode the action to. </td></tr>
    <tr><td valign="top"></td><td valign="top"><em>action</em>&nbsp;</td><td>The action to encode. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="a95df691c5e041ad619f07632da6fa706"></a><!-- doxytag: member="Agent::encodePercept" ref="a95df691c5e041ad619f07632da6fa706" args="(symbol_list_t &amp;symlist, percept_t observation, percept_t reward) const " -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void Agent::encodePercept </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="main_8hpp.html#a96913eb6aee99146c546467f52cf18dc">symbol_list_t</a> &amp;&nbsp;</td>
          <td class="paramname"> <em>symlist</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="main_8hpp.html#ae876c1434cd64208efe3bc215e4391f4">percept_t</a>&nbsp;</td>
          <td class="paramname"> <em>observation</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="main_8hpp.html#ae876c1434cd64208efe3bc215e4391f4">percept_t</a>&nbsp;</td>
          <td class="paramname"> <em>reward</em></td><td>&nbsp;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td><td> const<code> [private]</code></td>
        </tr>
      </table>
</div>
<div class="memdoc">
<p>Encode a percept as a list of symbols. </p>
<dl><dt><b>Parameters:</b></dt><dd>
  <table border="0" cellspacing="2" cellpadding="0">
    <tr><td valign="top"></td><td valign="top"><em>symlist</em>&nbsp;</td><td>The symbol list to encode the percept to. </td></tr>
    <tr><td valign="top"></td><td valign="top"><em>observation</em>&nbsp;</td><td>The observation part of the percept to encode. </td></tr>
    <tr><td valign="top"></td><td valign="top"><em>reward</em>&nbsp;</td><td>The reward part of the percept to encode. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="a4d7516fc4fa235579bec105c59a116a5"></a><!-- doxytag: member="Agent::genAction" ref="a4d7516fc4fa235579bec105c59a116a5" args="() const " -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="main_8hpp.html#aae5c472255c22ac4ca225a8b856d6617">action_t</a> Agent::genAction </td>
          <td>(</td>
          <td class="paramtype">void&nbsp;</td>
          <td class="paramname"></td>
          <td>&nbsp;)&nbsp;</td>
          <td> const</td>
        </tr>
      </table>
</div>
<div class="memdoc">
<p>Generate an action distributed according to the agent's history statistics by doing rejection sampling from the context tree. </p>
<dl class="return"><dt><b>Returns:</b></dt><dd>The generated action. </dd></dl>

</div>
</div>
<a class="anchor" id="a355ffd0b425d575d458f55a6d3be3146"></a><!-- doxytag: member="Agent::genPercept" ref="a355ffd0b425d575d458f55a6d3be3146" args="(percept_t &amp;observation, percept_t &amp;reward)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void Agent::genPercept </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="main_8hpp.html#ae876c1434cd64208efe3bc215e4391f4">percept_t</a> &amp;&nbsp;</td>
          <td class="paramname"> <em>observation</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="main_8hpp.html#ae876c1434cd64208efe3bc215e4391f4">percept_t</a> &amp;&nbsp;</td>
          <td class="paramname"> <em>reward</em></td><td>&nbsp;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td><td></td>
        </tr>
      </table>
</div>
<div class="memdoc">
<p>Generate a percept distributed according to the agent's history statistics by sampling from the context tree. </p>
<dl><dt><b>Parameters:</b></dt><dd>
  <table border="0" cellspacing="2" cellpadding="0">
    <tr><td valign="top"></td><td valign="top"><em>observation</em>&nbsp;</td><td>Receives the observation part of the generated percept. </td></tr>
    <tr><td valign="top"></td><td valign="top"><em>reward</em>&nbsp;</td><td>Receives the reward part of the generated percept. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="a5f1e9d7b8406d71ea2b031c259662496"></a><!-- doxytag: member="Agent::genPerceptAndUpdate" ref="a5f1e9d7b8406d71ea2b031c259662496" args="(percept_t &amp;observation, percept_t &amp;reward)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void Agent::genPerceptAndUpdate </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="main_8hpp.html#ae876c1434cd64208efe3bc215e4391f4">percept_t</a> &amp;&nbsp;</td>
          <td class="paramname"> <em>observation</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="main_8hpp.html#ae876c1434cd64208efe3bc215e4391f4">percept_t</a> &amp;&nbsp;</td>
          <td class="paramname"> <em>reward</em></td><td>&nbsp;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td><td></td>
        </tr>
      </table>
</div>
<div class="memdoc">
<p>Generate a percept distributed according to the agent's history statistics, and update the context tree with it. </p>
<dl><dt><b>Parameters:</b></dt><dd>
  <table border="0" cellspacing="2" cellpadding="0">
    <tr><td valign="top"></td><td valign="top"><em>observation</em>&nbsp;</td><td>Receives the observation part of the generated percept. </td></tr>
    <tr><td valign="top"></td><td valign="top"><em>reward</em>&nbsp;</td><td>Receives the reward part of the generated percept. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="ae785bc53214dc592055779ad40004dee"></a><!-- doxytag: member="Agent::genRandomAction" ref="ae785bc53214dc592055779ad40004dee" args="() const " -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="main_8hpp.html#aae5c472255c22ac4ca225a8b856d6617">action_t</a> Agent::genRandomAction </td>
          <td>(</td>
          <td class="paramtype">void&nbsp;</td>
          <td class="paramname"></td>
          <td>&nbsp;)&nbsp;</td>
          <td> const</td>
        </tr>
      </table>
</div>
<div class="memdoc">
<p>Generate an action uniformly at random. </p>
<dl class="return"><dt><b>Returns:</b></dt><dd>The generated action. </dd></dl>

</div>
</div>
<a class="anchor" id="a26f277b7001f56a48219c24d702d8c3e"></a><!-- doxytag: member="Agent::getPredictedActionProb" ref="a26f277b7001f56a48219c24d702d8c3e" args="(action_t action)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">double Agent::getPredictedActionProb </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="main_8hpp.html#aae5c472255c22ac4ca225a8b856d6617">action_t</a>&nbsp;</td>
          <td class="paramname"> <em>action</em></td>
          <td>&nbsp;)&nbsp;</td>
          <td></td>
        </tr>
      </table>
</div>
<div class="memdoc">
<p>Probability of selecting an action according to the agent's internal model of it's own behaviour. </p>
<dl><dt><b>Parameters:</b></dt><dd>
  <table border="0" cellspacing="2" cellpadding="0">
    <tr><td valign="top"></td><td valign="top"><em>action</em>&nbsp;</td><td>The action we wish to find the likelihood of. </td></tr>
  </table>
  </dd>
</dl>
<dl class="return"><dt><b>Returns:</b></dt><dd>The probability of the agent selecting action. </dd></dl>

</div>
</div>
<a class="anchor" id="a94f6ec9baf65e862f5643857ee7c575b"></a><!-- doxytag: member="Agent::historySize" ref="a94f6ec9baf65e862f5643857ee7c575b" args="() const " -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int Agent::historySize </td>
          <td>(</td>
          <td class="paramtype">void&nbsp;</td>
          <td class="paramname"></td>
          <td>&nbsp;)&nbsp;</td>
          <td> const</td>
        </tr>
      </table>
</div>
<div class="memdoc">
<p>The length of the stored history for an agent. </p>

</div>
</div>
<a class="anchor" id="a4f86f50cdc91387ea31aef3e14e61912"></a><!-- doxytag: member="Agent::horizon" ref="a4f86f50cdc91387ea31aef3e14e61912" args="() const " -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int Agent::horizon </td>
          <td>(</td>
          <td class="paramtype">void&nbsp;</td>
          <td class="paramname"></td>
          <td>&nbsp;)&nbsp;</td>
          <td> const</td>
        </tr>
      </table>
</div>
<div class="memdoc">
<p>The length of the search horizon used by the agent. </p>

</div>
</div>
<a class="anchor" id="a8d732dca2ad60a250c65f3c2112fba34"></a><!-- doxytag: member="Agent::lastUpdate" ref="a8d732dca2ad60a250c65f3c2112fba34" args="(void) const " -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="agent_8hpp.html#accbaf2fbd73874d4101d738a22205dc3">update_t</a> Agent::lastUpdate </td>
          <td>(</td>
          <td class="paramtype">void&nbsp;</td>
          <td class="paramname"></td>
          <td>&nbsp;)&nbsp;</td>
          <td> const<code> [inline]</code></td>
        </tr>
      </table>
</div>
<div class="memdoc">
<p>True if the last update was a percept, false if it was an action. </p>

</div>
</div>
<a class="anchor" id="a83cbf224d699d2ef2ce74848656cc3f9"></a><!-- doxytag: member="Agent::maxAction" ref="a83cbf224d699d2ef2ce74848656cc3f9" args="() const " -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int Agent::maxAction </td>
          <td>(</td>
          <td class="paramname"></td>
          <td>&nbsp;)&nbsp;</td>
          <td> const<code> [inline]</code></td>
        </tr>
      </table>
</div>
<div class="memdoc">
<p>The "maximum" action the agent can execute. </p>

</div>
</div>
<a class="anchor" id="a4dc611cbe426034f0af35823a489221b"></a><!-- doxytag: member="Agent::maxBitsNeeded" ref="a4dc611cbe426034f0af35823a489221b" args="() const " -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int Agent::maxBitsNeeded </td>
          <td>(</td>
          <td class="paramname"></td>
          <td>&nbsp;)&nbsp;</td>
          <td> const</td>
        </tr>
      </table>
</div>
<div class="memdoc">
<p>The maximum number of bits to encode either an action or percept. </p>

</div>
</div>
<a class="anchor" id="a5a234203ccae48c9a241a6e40c7887f6"></a><!-- doxytag: member="Agent::maxReward" ref="a5a234203ccae48c9a241a6e40c7887f6" args="() const " -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">double Agent::maxReward </td>
          <td>(</td>
          <td class="paramname"></td>
          <td>&nbsp;)&nbsp;</td>
          <td> const<code> [inline]</code></td>
        </tr>
      </table>
</div>
<div class="memdoc">
<p>The maximum possible reward the agent can receive in a single cycle. </p>

</div>
</div>
<a class="anchor" id="a464e7b5139527b39986d6f53487b6f6b"></a><!-- doxytag: member="Agent::modelRevert" ref="a464e7b5139527b39986d6f53487b6f6b" args="(const ModelUndo &amp;mu)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void Agent::modelRevert </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classModelUndo.html">ModelUndo</a> &amp;&nbsp;</td>
          <td class="paramname"> <em>mu</em></td>
          <td>&nbsp;)&nbsp;</td>
          <td></td>
        </tr>
      </table>
</div>
<div class="memdoc">
<p>Revert the agent's model of the world to that of a previous time cycle. </p>

</div>
</div>
<a class="anchor" id="ad859620dd26557127c7221311089e00e"></a><!-- doxytag: member="Agent::modelSize" ref="ad859620dd26557127c7221311089e00e" args="() const " -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int Agent::modelSize </td>
          <td>(</td>
          <td class="paramname"></td>
          <td>&nbsp;)&nbsp;</td>
          <td> const</td>
        </tr>
      </table>
</div>
<div class="memdoc">

</div>
</div>
<a class="anchor" id="adf4845b694cd4e2f6b9b02270b2e6040"></a><!-- doxytag: member="Agent::modelUpdate" ref="adf4845b694cd4e2f6b9b02270b2e6040" args="(action_t action)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void Agent::modelUpdate </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="main_8hpp.html#aae5c472255c22ac4ca225a8b856d6617">action_t</a>&nbsp;</td>
          <td class="paramname"> <em>action</em></td>
          <td>&nbsp;)&nbsp;</td>
          <td></td>
        </tr>
      </table>
</div>
<div class="memdoc">
<p>Update the agent's model of the world after performing an action. </p>
<dl><dt><b>Parameters:</b></dt><dd>
  <table border="0" cellspacing="2" cellpadding="0">
    <tr><td valign="top"></td><td valign="top"><em>action</em>&nbsp;</td><td>The action that the agent performed. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="a5d7e42a9677cc6c5a8bcb236f36ddb0a"></a><!-- doxytag: member="Agent::modelUpdate" ref="a5d7e42a9677cc6c5a8bcb236f36ddb0a" args="(percept_t observation, percept_t reward)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void Agent::modelUpdate </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="main_8hpp.html#ae876c1434cd64208efe3bc215e4391f4">percept_t</a>&nbsp;</td>
          <td class="paramname"> <em>observation</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="main_8hpp.html#ae876c1434cd64208efe3bc215e4391f4">percept_t</a>&nbsp;</td>
          <td class="paramname"> <em>reward</em></td><td>&nbsp;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td><td></td>
        </tr>
      </table>
</div>
<div class="memdoc">
<p>Update the agent's model of the world with a percept from the environment </p>
<dl><dt><b>Parameters:</b></dt><dd>
  <table border="0" cellspacing="2" cellpadding="0">
    <tr><td valign="top"></td><td valign="top"><em>observation</em>&nbsp;</td><td>The observation that was received. </td></tr>
    <tr><td valign="top"></td><td valign="top"><em>reward</em>&nbsp;</td><td>The reward that was received. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="af73c945cfc7f20619bbaea03c07c72be"></a><!-- doxytag: member="Agent::perceptProbability" ref="af73c945cfc7f20619bbaea03c07c72be" args="(percept_t observation, percept_t reward) const " -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">double Agent::perceptProbability </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="main_8hpp.html#ae876c1434cd64208efe3bc215e4391f4">percept_t</a>&nbsp;</td>
          <td class="paramname"> <em>observation</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="main_8hpp.html#ae876c1434cd64208efe3bc215e4391f4">percept_t</a>&nbsp;</td>
          <td class="paramname"> <em>reward</em></td><td>&nbsp;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td><td> const</td>
        </tr>
      </table>
</div>
<div class="memdoc">
<p>Probability of receiving a particular percept (observation and reward) according to the agent's environment model. </p>
<dl><dt><b>Parameters:</b></dt><dd>
  <table border="0" cellspacing="2" cellpadding="0">
    <tr><td valign="top"></td><td valign="top"><em>observation</em>&nbsp;</td><td>The observation part of the percept we wish to find the likelihood of. </td></tr>
    <tr><td valign="top"></td><td valign="top"><em>reward</em>&nbsp;</td><td>The reward part of the percept we wish to find the likelihood of. </td></tr>
  </table>
  </dd>
</dl>
<dl class="return"><dt><b>Returns:</b></dt><dd>The probability of observing the (observation, reward) pair. </dd></dl>

</div>
</div>
<a class="anchor" id="a0f38a1f8ff4ca66eb1adaea3c38261d9"></a><!-- doxytag: member="Agent::playout" ref="a0f38a1f8ff4ca66eb1adaea3c38261d9" args="(int horizon)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="main_8hpp.html#a008010a51f193f33b2e94c75e10d30b2">reward_t</a> Agent::playout </td>
          <td>(</td>
          <td class="paramtype">int&nbsp;</td>
          <td class="paramname"> <em>horizon</em></td>
          <td>&nbsp;)&nbsp;</td>
          <td></td>
        </tr>
      </table>
</div>
<div class="memdoc">
<p>Simulate agent/enviroment interaction for a specified amount of steps where agent actions are chosen uniformly at random and percepts are generated from the agents environment model. </p>
<dl><dt><b>Parameters:</b></dt><dd>
  <table border="0" cellspacing="2" cellpadding="0">
    <tr><td valign="top"></td><td valign="top"><em>agent</em>&nbsp;</td><td>The agent doing the sampling. </td></tr>
    <tr><td valign="top"></td><td valign="top"><em>playout_len</em>&nbsp;</td><td>The number of complete action/percept steps to simulate. </td></tr>
  </table>
  </dd>
</dl>
<dl class="return"><dt><b>Returns:</b></dt><dd>The total reward from the simulation. </dd></dl>

</div>
</div>
<a class="anchor" id="a5dc4ba18b66815d10359e458b0e5d867"></a><!-- doxytag: member="Agent::reset" ref="a5dc4ba18b66815d10359e458b0e5d867" args="(void)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void Agent::reset </td>
          <td>(</td>
          <td class="paramtype">void&nbsp;</td>
          <td class="paramname"></td>
          <td>&nbsp;)&nbsp;</td>
          <td></td>
        </tr>
      </table>
</div>
<div class="memdoc">
<p>Resets the agent and clears the context tree. </p>

</div>
</div>
<a class="anchor" id="ac2477fa04e05470c2c7dd80ae291a4fc"></a><!-- doxytag: member="Agent::search" ref="ac2477fa04e05470c2c7dd80ae291a4fc" args="(void)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="main_8hpp.html#aae5c472255c22ac4ca225a8b856d6617">action_t</a> Agent::search </td>
          <td>(</td>
          <td class="paramtype">void&nbsp;</td>
          <td class="paramname"></td>
          <td>&nbsp;)&nbsp;</td>
          <td></td>
        </tr>
      </table>
</div>
<div class="memdoc">
<p>Determine the best action for the agent using Monte-Carlo Tree Search (predictive UCT). </p>
<dl class="return"><dt><b>Returns:</b></dt><dd>The best action as determined by the sampling. </dd></dl>

</div>
</div>
<a class="anchor" id="af0956c4cf5de1879b5c0efb3ad1e0f67"></a><!-- doxytag: member="Agent::totalReward" ref="af0956c4cf5de1879b5c0efb3ad1e0f67" args="() const " -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="main_8hpp.html#a008010a51f193f33b2e94c75e10d30b2">reward_t</a> Agent::totalReward </td>
          <td>(</td>
          <td class="paramtype">void&nbsp;</td>
          <td class="paramname"></td>
          <td>&nbsp;)&nbsp;</td>
          <td> const</td>
        </tr>
      </table>
</div>
<div class="memdoc">
<p>The total accumulated reward across an agents lifespan. </p>

</div>
</div>
<hr/><h2>Field Documentation</h2>
<a class="anchor" id="a74dd45989bc1b5128788cbe4a0f2ae37"></a><!-- doxytag: member="Agent::m_ct" ref="a74dd45989bc1b5128788cbe4a0f2ae37" args="" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classContextTree.html">ContextTree</a>* <a class="el" href="classAgent.html#a74dd45989bc1b5128788cbe4a0f2ae37">Agent::m_ct</a><code> [private]</code></td>
        </tr>
      </table>
</div>
<div class="memdoc">
<p>Context tree representing the agent's model of the environment. </p>

</div>
</div>
<a class="anchor" id="aa5c1d62784eb31e8eb41cad1431dba53"></a><!-- doxytag: member="Agent::m_env" ref="aa5c1d62784eb31e8eb41cad1431dba53" args="" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classEnvironment.html">Environment</a> const&amp; <a class="el" href="classAgent.html#aa5c1d62784eb31e8eb41cad1431dba53">Agent::m_env</a><code> [private]</code></td>
        </tr>
      </table>
</div>
<div class="memdoc">
<p>A reference to the environment the agent interacts with. </p>

</div>
</div>
<a class="anchor" id="abe3b766fdc5c7e7e1970b0e13de2cf3b"></a><!-- doxytag: member="Agent::m_horizon" ref="abe3b766fdc5c7e7e1970b0e13de2cf3b" args="" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int <a class="el" href="classAgent.html#abe3b766fdc5c7e7e1970b0e13de2cf3b">Agent::m_horizon</a><code> [private]</code></td>
        </tr>
      </table>
</div>
<div class="memdoc">
<p>The length of the agent's planning horizon. </p>

</div>
</div>
<a class="anchor" id="ab2f8cb6e7035f0b88c2dc455d26cefc0"></a><!-- doxytag: member="Agent::m_last_update" ref="ab2f8cb6e7035f0b88c2dc455d26cefc0" args="" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="agent_8hpp.html#accbaf2fbd73874d4101d738a22205dc3">update_t</a> <a class="el" href="classAgent.html#ab2f8cb6e7035f0b88c2dc455d26cefc0">Agent::m_last_update</a><code> [private]</code></td>
        </tr>
      </table>
</div>
<div class="memdoc">
<p>The type of the last update (action or percept). </p>

</div>
</div>
<a class="anchor" id="a6909f2e3a2431c7e6bc7a574cdea2c56"></a><!-- doxytag: member="Agent::m_learning_period" ref="a6909f2e3a2431c7e6bc7a574cdea2c56" args="" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int <a class="el" href="classAgent.html#a6909f2e3a2431c7e6bc7a574cdea2c56">Agent::m_learning_period</a><code> [private]</code></td>
        </tr>
      </table>
</div>
<div class="memdoc">
<p>The number of cycles during which the agent learns. </p>

</div>
</div>
<a class="anchor" id="a247ae06b17ed43159d3fffce0b444fa3"></a><!-- doxytag: member="Agent::m_mc_simulations" ref="a247ae06b17ed43159d3fffce0b444fa3" args="" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int <a class="el" href="classAgent.html#a247ae06b17ed43159d3fffce0b444fa3">Agent::m_mc_simulations</a><code> [private]</code></td>
        </tr>
      </table>
</div>
<div class="memdoc">
<p>The number of simulations to conduct when choosing new actions via the UCT algorithm. </p>

</div>
</div>
<a class="anchor" id="a4b5e2ba976ad0f397d0d0591ea7faebf"></a><!-- doxytag: member="Agent::m_options" ref="a4b5e2ba976ad0f397d0d0591ea7faebf" args="" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="main_8hpp.html#a0ff5cac1a4007bb330b7d9939650c283">options_t</a>&amp; <a class="el" href="classAgent.html#a4b5e2ba976ad0f397d0d0591ea7faebf">Agent::m_options</a><code> [private]</code></td>
        </tr>
      </table>
</div>
<div class="memdoc">
<p>Stores the configuration options. </p>

</div>
</div>
<a class="anchor" id="a00b3ccf57df47e369a01b0a80b0155f3"></a><!-- doxytag: member="Agent::m_search_tree" ref="a00b3ccf57df47e369a01b0a80b0155f3" args="" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classSearchNode.html">SearchNode</a>* <a class="el" href="classAgent.html#a00b3ccf57df47e369a01b0a80b0155f3">Agent::m_search_tree</a><code> [private]</code></td>
        </tr>
      </table>
</div>
<div class="memdoc">
<p>The root node of the UCT search tree. </p>

</div>
</div>
<a class="anchor" id="acd27d5d9fa97749bffe84671cb9bb1ee"></a><!-- doxytag: member="Agent::m_time_cycle" ref="acd27d5d9fa97749bffe84671cb9bb1ee" args="" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="main_8hpp.html#afc9884d9296b2bc1fc412248318128a9">age_t</a> <a class="el" href="classAgent.html#acd27d5d9fa97749bffe84671cb9bb1ee">Agent::m_time_cycle</a><code> [private]</code></td>
        </tr>
      </table>
</div>
<div class="memdoc">
<p>The number of interaction cycles the agent has been alive. </p>

</div>
</div>
<a class="anchor" id="a341264ac3d700120cfd1c50ab35c60ab"></a><!-- doxytag: member="Agent::m_total_reward" ref="a341264ac3d700120cfd1c50ab35c60ab" args="" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="main_8hpp.html#a008010a51f193f33b2e94c75e10d30b2">reward_t</a> <a class="el" href="classAgent.html#a341264ac3d700120cfd1c50ab35c60ab">Agent::m_total_reward</a><code> [private]</code></td>
        </tr>
      </table>
</div>
<div class="memdoc">
<p>The total reward received by the agent. </p>

</div>
</div>
<hr/>The documentation for this class was generated from the following files:<ul>
<li><a class="el" href="agent_8hpp_source.html">agent.hpp</a></li>
<li><a class="el" href="agent_8cpp.html">agent.cpp</a></li>
</ul>
</div>
<hr class="footer"/><address class="footer"><small>Generated on Sat Apr 23 2011 11:53:08 for MC-AIXI-CTW by&nbsp;
<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.7.1 </small></address>
</body>
</html>
